# Lec 3: GFS

Lec3 一上来就说去看谷歌的论文，那就去看吧。

看完回来，讲的并不是谷歌的 GFS，讲的是带容错虚拟机。

主要内容是讲如何通过两个虚拟机 Primary 和 Backup 来实现容错，即在 Primary 挂掉的时候，Backup 能够接管 Primary 的工作。

简单的存储接口往往更加有用且通用，构建分布式系统大多数都是关于如何设计存储系统。

> 感觉我看的 20 版本这里可能就直接讲 GFS 了，25 版本改成讲 Fault-Tolerant 了？先看吧，无所谓了。

为什么分布式存储系统难？

分片：数据量太大，单机存储不下，需要分片存储在多台机器上，但是总是会有机器挂掉。不可能人工纠正，所以需要纠错机制，比如 Fault-Tolerant。如果想要有容错，那就必须复制。如果采用复制，就可能会碰到奇怪的问题。为了解决奇怪的问题，需要额外的设计保持一致性，然后性能就会变低，就违背了我们最开始高性能的初衷

强一致性可以理解为虽然有数百台机子，但是用户感觉就像只有一台机子一样。

为了实现强一致性，付出的代价很大。

有一个问题就是 C1 对 S1 写入数据，然后 C2 对 S2 读取数据，如果 S2 还没有收到 S1 的数据，那么 C2 读取到的就是旧数据。

GFS 如何修复这些问题？

一个存储系统需要大而快。通用可重复。可自动纠错。单数据中心（为大文件专门定制的，大文件的顺序访问）

这篇论文开创性的提出了弱一致性是可以接受的。因为你并不关心 20000 条检索数据的排序有 1 条错误。

上百个客户端和一个 master（master 会有副本）。然后 master 负责保存 kv 信息，chunk server 负责存储数据块。chunk 是 64MB 的大块数据。

如果想知道哪个文件在哪，只需要问 master，master 会告诉你哪个 chunk server 上有这个 chunk。

master 存储的是什么？

master 主要存储两个东西。

第一个是 filename 到 chunk ID 数组的映射；

第二张表是每个 chunk handle 到一些数据的映射，其中一项是 chunk server 的列表，每个 chunk 都有自己的版本，所以还需要记录所有的 chunk 的版本号；还需要记录哪个 chunk server 是 primary 以及他们的过期时间（在某段时间内这个是 primary）

master 在磁盘上还应该有一个 log，用于定时创建 checkpoint。

理解这些数据和数据中的操作。

read。

1. 计算：客户端根据文件名和偏移量，自己算出 Chunk Index。
2. 询问：客户端向 Master 发送请求：{文件名, Chunk Index}。
3. 查询：Master 查表，找到对应的 Chunk Handle 和 副本位置列表。
4. 响应：Master 把这些信息发回给客户端。
5. 缓存：客户端把这些元数据缓存起来（Key 是文件名和 Chunk Index）。
6. 读取：客户端挑选一个最近的 Chunk Server，直接发送请求：{Chunk Handle, Byte Range}，读取数据。

write。

1. 询问与租约分配：客户端向管理节点询问：我想往这个数据块写数据，谁是主副本？次级副本在哪里？
    - 情况一：如果没有主副本。管理节点发现目前没有副本持有租约。它会从现有的副本中挑选一个，授予它租约，让它成为主副本。同时，管理节点会增加该数据块的版本号，并通知所有副本更新版本号。完成后，管理节点将主副本和次级副本的位置信息返回给客户端。
    - 情况二：如果已经有主副本。管理节点发现已经有一个副本持有有效的租约。它直接将当前的主副本和次级副本的位置信息返回给客户端。
2. 缓存：客户端收到位置信息后，将这些元数据缓存起来，以后这就不用每次都问管理节点了。
3. 推送数据：客户端将数据推送到所有的副本上。这里利用了流水线技术，客户端把数据发给网络距离最近的节点，那个节点收到后再传给下一个节点，以此类推。此时数据只是暂时存在副本的内存缓冲区里，还没有真正写入磁盘。
4. 发送写请求。当所有副本都确认收到数据后，客户端向主副本发送正式的写请求。
5. 定序与写入。主副本收到请求后，为这个写操作分配一个唯一的序列号，确立操作的执行顺序。然后，主副本按照这个顺序在本地执行写入操作。
6. 转发指令。主副本将写请求连同刚才分配的序列号，一起转发给所有的次级副本，要求它们必须严格按照相同的序列号顺序执行写入。
7. 确认。所有的次级副本执行完写入操作后，向主副本发送完成确认。
8. 响应。主副本收到了所有次级副本的确认信息后，回复客户端写入成功。

感觉 20 版的这一章后四分三就是在讲 GFS 啊，稍微听了听，但是没仔细记笔记。

直接去写 lab2 了。
